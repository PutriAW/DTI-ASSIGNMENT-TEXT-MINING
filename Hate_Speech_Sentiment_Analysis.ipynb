{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hate Speech Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeQJiMLSFREpJJeV1tFBq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PutriAW/DTI-ASSIGNMENT-TEXT-MINING/blob/main/Hate_Speech_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foers9b76Shz"
      },
      "source": [
        "## **Hate Speech Sentiment Analysis**\n",
        "Created By Putri Apriyanti Windya \n",
        " (DS0124 - Data Scientist 01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI2nFDrm6XHp"
      },
      "source": [
        "# **Dataset**\n",
        "\n",
        "---\n",
        " Dataset for this classification obtained from https://raw.githubusercontent.com/ialfina/id-hatespeech-detection/master/IDHSD_RIO_unbalanced_713_2017.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m9VAiQw6qnn"
      },
      "source": [
        "# **Description**\n",
        "\n",
        "---\n",
        "\n",
        "The Dataset for Hate Speech Detection in Indonesian\n",
        "(Dataset untuk Deteksi Ujaran Kebencian dalam Bahasa Indonesia)\n",
        "\n",
        "Dataset\n",
        "The dataset is a two columns data of: label - tweet, consist of 713 tweets in Indonesian.\n",
        "The label is Non_HS or HS. Non_HS for \"non-hate-speech\" tweet and HS for \"hate-speech\" tweet.\n",
        "\n",
        "Number of Non_HS tweets: 453\n",
        "Number of HS tweets: 260\n",
        "Since this dataset is unbalanced, you might have to do over-sampling/down-sampling in order to create a balanced dataset.\n",
        "The dataset may be used freely, but if you want to publish paper/publication using the dataset, please cite this publication:\n",
        "\n",
        "Ika Alfina, Rio Mulia, Mohamad Ivan Fanany, and Yudo Ekanata, \"Hate Speech Detection in Indonesian Language: A Dataset and Preliminary Study \", in Proceeding of 9th International Conference on Advanced Computer Science and Information Systems 2017(ICACSIS 2017)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3axp-EC7EwT"
      },
      "source": [
        "# **Problem to Solve**\n",
        "\n",
        "---\n",
        "\n",
        "Do sentiment Analysis to know whether a twitter tweet is hate speech or non hate speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rohc2De7vMl"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAP5a4Aj71MA"
      },
      "source": [
        "## **Data Exploration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2naRgoNn795d"
      },
      "source": [
        "**Import All Libraries that Needed for Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmymABjvhhD_",
        "outputId": "2e2d1c4c-335d-4568-9149-4aedef6f6f05"
      },
      "source": [
        "# Install library for text preprocessing\n",
        "!pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luABDyAIhyVt",
        "outputId": "ac314017-6712-4b00-dcce-ed6e5ff94c68"
      },
      "source": [
        "# install library for indonesian language stemming\n",
        "!pip install Sastrawi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VBGoCLf8Cp7"
      },
      "source": [
        "# Import Library\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import requests\n",
        "import io\n",
        "import re # regular expression\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9-rw4pUzRUJ"
      },
      "source": [
        "# Get Data from Github\n",
        "result = requests.get('https://raw.githubusercontent.com/ialfina/id-hatespeech-detection/master/IDHSD_RIO_unbalanced_713_2017.txt')\n",
        "data = io.StringIO(result.text)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "uFTPvTV6zZK0",
        "outputId": "78d629ae-3233-4e66-e6ed-b8044b7ac851"
      },
      "source": [
        "# Convert result into data frame\n",
        "df_hs = pd.read_csv(data, sep='\\t')\n",
        "df_hs.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Label                                              Tweet\n",
              "0  Non_HS  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...\n",
              "1  Non_HS  RT @baguscondromowo: Mereka terus melukai aksi...\n",
              "2  Non_HS  Sylvi: bagaimana gurbernur melakukan kekerasan...\n",
              "3  Non_HS  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...\n",
              "4  Non_HS  RT @lisdaulay28: Waspada KTP palsu.....kawal P..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ouZkCsO23O84",
        "outputId": "5ff6122b-212d-4562-c894-f13792b037c1"
      },
      "source": [
        "# Count HS and Non_HS label\n",
        "df_hs.Label.value_counts().to_frame()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Non_HS</th>\n",
              "      <td>453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HS</th>\n",
              "      <td>260</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label\n",
              "Non_HS    453\n",
              "HS        260"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oba8U79I3PhJ"
      },
      "source": [
        "## **Text Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ClhwUSB3ZV3"
      },
      "source": [
        "**Case folding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "rYnp4pXtk_mW",
        "outputId": "b7009a20-459f-49bb-c0f7-b5143bc0d618"
      },
      "source": [
        "temp_tweet = []\n",
        "\n",
        "for tw in df_hs['Tweet']:\n",
        "  # removal of @name[mention]\n",
        "  tw = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", tw)\n",
        "\n",
        "  # removal of links[https://blabala.com]\n",
        "  # tw = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"\", tw)\n",
        "  tw = re.sub(r\"http\\S+\", \"\", tw)\n",
        "\n",
        "  # removal of new line\n",
        "  tw = re.sub('\\n', '', tw)\n",
        "\n",
        "  # removal of RT\n",
        "  tw = re.sub('RT', '', tw)\n",
        "\n",
        "  # Tokenization\n",
        "  # removal of punctuations and numbers\n",
        "  tw = re.sub(\"[^a-zA-Z^']\", \" \", tw)\n",
        "  tw = re.sub(\" {2,}\", \" \", tw)\n",
        "\n",
        "  # remove leading and trailing whitespace\n",
        "  tw = tw.strip()\n",
        "\n",
        "  # remove whitespace with a single space\n",
        "  tw = re.sub(r'\\s+', ' ', tw)\n",
        "\n",
        "  # convert text to Lowercase\n",
        "  tw = tw.lower();\n",
        "  temp_tweet.append(tw)\n",
        "\n",
        "df_hs['Clean_Tweet'] = temp_tweet\n",
        "df_hs.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Clean_Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
              "      <td>fadli zon minta mendagri segera menonaktifkan ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
              "      <td>mereka terus melukai aksi dalam rangka memenja...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
              "      <td>sylvi bagaimana gurbernur melakukan kekerasan ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
              "      <td>ahmad dhani tak puas debat pilkada masalah jal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
              "      <td>waspada ktp palsu kawal pilkada</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Label  ...                                        Clean_Tweet\n",
              "0  Non_HS  ...  fadli zon minta mendagri segera menonaktifkan ...\n",
              "1  Non_HS  ...  mereka terus melukai aksi dalam rangka memenja...\n",
              "2  Non_HS  ...  sylvi bagaimana gurbernur melakukan kekerasan ...\n",
              "3  Non_HS  ...  ahmad dhani tak puas debat pilkada masalah jal...\n",
              "4  Non_HS  ...                    waspada ktp palsu kawal pilkada\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVzTbkX89E0j"
      },
      "source": [
        "**Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6_9yADs9EAx"
      },
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def stem(tweet) :\n",
        "    hasil = stemmer.stem(tweet)\n",
        "    return hasil\n",
        "\n",
        "df_hs['Clean_Tweet'] = df_hs.apply(lambda row : stem(row['Clean_Tweet']), axis = 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKMHtUFp9YTv"
      },
      "source": [
        "**Stop Word Removal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TaYNmVm9Ys7"
      },
      "source": [
        "R_factory = StopWordRemoverFactory()\n",
        "R_stopword = R_factory.create_stop_word_remover()\n",
        "\n",
        "def R_stopwords(tweet) :\n",
        "    tweet = tweet.translate(str.maketrans('','',string.punctuation)).lower()\n",
        "    return R_stopword.remove(tweet)\n",
        "\n",
        "df_hs['Clean_Tweet'] = df_hs.apply(lambda row : stem(row['Clean_Tweet']), axis = 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "F9utzdcA-DYR",
        "outputId": "8ca1792f-db39-448a-d355-4b259198ef8d"
      },
      "source": [
        "df_hs.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Clean_Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
              "      <td>fadli zon minta mendagri segera nonaktif ahok ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
              "      <td>mereka terus luka aksi dalam rangka penjara ah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
              "      <td>sylvi bagaimana gurbernur laku keras perempuan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
              "      <td>ahmad dhani tak puas debat pilkada masalah jal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
              "      <td>waspada ktp palsu kawal pilkada</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Label  ...                                        Clean_Tweet\n",
              "0  Non_HS  ...  fadli zon minta mendagri segera nonaktif ahok ...\n",
              "1  Non_HS  ...  mereka terus luka aksi dalam rangka penjara ah...\n",
              "2  Non_HS  ...  sylvi bagaimana gurbernur laku keras perempuan...\n",
              "3  Non_HS  ...  ahmad dhani tak puas debat pilkada masalah jal...\n",
              "4  Non_HS  ...                    waspada ktp palsu kawal pilkada\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}